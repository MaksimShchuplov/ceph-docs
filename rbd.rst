RBD
---

.. include:: rbd-qemu.rst

Недорасписанное
+++++++++++++++

* опции для рбд образов типа фастдифф
* бага с удалением снапшотов созданных ранними версиями
* откат к снапшоту крайне медленный (как он работает) и что без дедупликации по сравнению со старыми
  объектам

* Виды кеширования в квм - дока от сусе где демелиоратор сказал что он не прав.
  И описание что есть потеря данных при вырубания питания.

  * https://www.spinics.net/lists/ceph-users/msg15983.html
  * http://docs.ceph.com/docs/master/rbd/qemu-rbd/#qemu-cache-options
  * https://github.com/ceph/ceph/pull/10797

* скруб еррор -- как понять хотябы какой это образ.
* как бекапить :)
* в рбд сразу после снапшота будут наблюдаться тормоза так как 4-мб объекты будут копироваться целиком даже при записи одного сектора.
* оборванное удаление образа. как доудалить остатки.
* Ядерный драйвер RBD не умеет во много опций. в частности, фастдифф. Варианты -- FUSEmount -- каждый файл это образ. либо NBD.
* iscsi
* qemu-nbd vs rbd-nbd
* преобразование в qcow2 и обратно. сжатие qcow2. Перенос в другой пул средством
  qemu-img. хотя более быстро -- на уровне rados.
* Перенос образов между пулами и копирование образов: рекомендуется qemu-img версии
  более 2.9.

  .. image:: _static/qemu-img-bandwith.jpg
     :alt: График пропускной способности

  https://github.com/qemu/qemu/commit/2d9187bc65727d9dd63e2c410b5500add3db0b0d и описание опций.

  .. code-block:: sh

     $ qemu-img convert -m 16 -W -p -n -f raw -O raw \
     rbd:<from_your_pool>/<you_volume>
     rbd:<to_your_pool>/<you_volume>

  Это если ceph.conf настроен. Можно вообще без него:

  .. code-block:: sh

     $ qemu-img convert -p -n -f raw -O raw \
     rbd:<from_your_pool>/<your_volume>:id=cinder:key=<cinder_key>:mon_host=172.16.16.2,172.16.16.3,172.16.16.4 \
     rbd:<to_your_pool>/<your_volume>:id=cinder:key=<cinder_key>:mon_host=172.16.16.2,172.16.16.3,172.16.16.4


* Сделав снапшот хотябы одного образа, сделать снапшот пула уже не получится. Узнать бы почему.
