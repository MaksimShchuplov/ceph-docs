==========
CloudMouse
==========

    Честно вам сказать из-за чего развалился? Ибо сам даже смотрел их кластер и пытался
    помочь... Помнится мне, что тогда еще актуальная версия ceph'а была firefly.
    Но им жутно не нравилась его производительность. Ну они и обновились, на в то время,
    не стабильный hammer. А когда пошли ошибки, то потом ещё и обновились аж на master ветку.
    А у мастер ветки была проблема связанная с утечкой памяти, ну и при нехватке памяти на
    сервере (еще один баг) убились данные. И количество репликаций у них было 2. Хотя и
    количество репликации бы тут не помогли. Так что CEPH там был не при чём. Банально админы
    накосячили, ну или их руководство.

    -- Аноним.


    И вроде еще вместо бекапов снапшоты использовали.

    -- `@socketpair <https://t.me/socketpair>`_


    Доброй ночи, всем.

    Спасибо всем пользователям, кто понял ситуацию, остался и создают виртуальные машины.
    Они действительно стали работать в 10-40раз быстрее, и это не связано с нагрузкой на облако.

    По поводу СХД, мы используем как минимум 8, с 3х кратной репликацией данных.
    Те "кусочек данных размером 1мб" хранится на 3х разных дисках на 3х СХД. А все данные хранятся
    примерно на 300+х дисках. Как мы ранее сообщали, проблема потери данных была связана с
    аппаратно-програмным сбоем в связки: ceph+rbd+osd+pg. Другими словами, все связи между блоками
    данных в кластере были утеряны.

    Еще раз, приносим свои извинения.
    По обращению в тикеты, мы помогаем настраивать сервера.
    По поводу компенсаций, мы планируем их зачислить на балансы в ближайшие дни.

    P.s. мы понимаем свою вину перед пользователи, но уверяем вас, мы нашли причины и исправили их.
    А многим облачным компаниям, еще только предстоит ее найти.

    -- https://searchengines.guru/showpost.php?p=13490140

    Ссылки:

    * https://habrahabr.ru/post/252221/
    * https://habrahabr.ru/post/250097/
